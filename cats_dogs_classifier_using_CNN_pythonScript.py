# -*- coding: utf-8 -*-
"""CNN_cat_dog_classifier (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LeHfbS0ZZYZYyCrCRiuRyEWXBs4Psb_8

Install libs
"""

!pip install opendatasets -q
!pip install numpy -q
!pip install pandas -q
!pip install matplotlib -q
!pip install tensorflow -q

"""Import libs"""

import tensorflow as tf
import opendatasets as od
import pandas as pd
import matplotlib.pyplot as plt
import time
import numpy as np

"""Download cats and dogs dataset from kaggle"""

od.download("https://www.kaggle.com/datasets/dineshpiyasamara/cats-and-dogs-for-classification")

"""Seperate batches and set image size"""

BATCH_SIZE = 32   #
IMAGE_SIZE = (128,128)    #   Input image shape

"""Set data for train and test"""

train_data_dir = "/content/cats-and-dogs-for-classification/cats_dogs/train"
test_data_dir = "/content/cats-and-dogs-for-classification/cats_dogs/test"

"""Split training into train data(0.9) and validation data(0.1) |
Set test data
"""

train_data = tf.keras.utils.image_dataset_from_directory(
    train_data_dir,
    batch_size=BATCH_SIZE,
    image_size=IMAGE_SIZE,
    subset='training',
    validation_split=0.1,
    seed=42
)

validation_data = tf.keras.utils.image_dataset_from_directory(
    train_data_dir,
    batch_size=BATCH_SIZE,
    image_size=IMAGE_SIZE,
    subset='validation',
    validation_split=0.1,
    seed=42
)

test_data = tf.keras.utils.image_dataset_from_directory(
    test_data_dir,
    batch_size=BATCH_SIZE,
    image_size=IMAGE_SIZE
)

class_names = train_data.class_names
class_names

for image_batch,label_batch in train_data.take(1):
  print(image_batch.shape)
  print(label_batch.shape)

"""Plot random images from the dataset"""

# Plot data sample
plt.figure(figsize=(10,4))
for image,label in train_data.take(1):
  for i in range(10):
    ax = plt.subplot(2,5,i+1)
    plt.imshow(image[i].numpy().astype('uint8'))
    plt.title(class_names[label[i]])
    plt.axis('off')

for image,label in train_data.take(1):
  for i in range(1):
    print(image)

# Normalize
train_data = train_data.map(lambda x,y:(x/255,y))
validation_data = validation_data.map(lambda x,y:(x/255,y))
test_data = test_data.map(lambda x,y:(x/255,y))

"""Data augmentation"""

data_augmentation = tf.keras.Sequential(
    [
        tf.keras.layers.RandomFlip("horizontal",input_shape=(128,128,3)),
        tf.keras.layers.RandomRotation(0.2),
        tf.keras.layers.RandomZoom(0.2),
    ]
)

"""Model buliding"""

model = tf.keras.models.Sequential()

model.add(data_augmentation)

model.add(tf.keras.layers.Conv2D(32,kernel_size=3,activation='relu'))
model.add(tf.keras.layers.MaxPooling2D())

model.add(tf.keras.layers.Conv2D(64,kernel_size=3,activation='relu'))
model.add(tf.keras.layers.MaxPooling2D())

model.add(tf.keras.layers.Conv2D(128,kernel_size=3,activation='relu'))
model.add(tf.keras.layers.MaxPooling2D())

model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.BatchNormalization())

model.add(tf.keras.layers.Flatten())

model.add(tf.keras.layers.Dense(128,activation='relu'))
model.add(tf.keras.layers.Dense(128,activation='relu'))
model.add(tf.keras.layers.Dense(64,activation='relu'))
model.add(tf.keras.layers.Dense(32,activation='relu'))

model.add(tf.keras.layers.Dense(1,activation='sigmoid'))

"""Model architecture"""

model.summary()

"""Compile the model"""

model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss=tf.keras.losses.BinaryCrossentropy(),
    metrics=['accuracy']
)

"""Train the model under 30 epochs. You can adjust it. Take some time, So better to run with T4 (in Colab) or under high performance"""

start_time = time.time()

history=model.fit(
    train_data,
    epochs=30,
    validation_data=validation_data
)

end_time = time.time()

"""Plot the Accuracy"""

fig = plt.figure()
plt.plot(history.history['accuracy'],color="red",label='accuracy')
plt.plot(history.history['val_accuracy'],color="green",label='val_accuracy')
fig.suptitle('Accuracy',fontsize=20)
plt.legend()
plt.show()

"""Plot losses"""

fig = plt.figure()
plt.plot(history.history['loss'],color="red",label='loss')
plt.plot(history.history['val_loss'],color="green",label='val_loss')
fig.suptitle('Loss',fontsize=20)
plt.legend()
plt.show()

precision = tf.keras.metrics.Precision()
recall = tf.keras.metrics.Recall()
accuracy = tf.keras.metrics.BinaryAccuracy()

"""Model already trained. Now lets see how to use this model."""

# !pip install opencv-python

import cv2 #import this for read images

img = cv2.imread('image path')
plt.imshow(img)
plt.show()

"""IMAGE_SIZE = (128,128) | We created the Input layer with 128 neurons.
Every pixel devide by 255 for better normalization
"""

resize = tf.image.resize(img,IMAGE_SIZE)
scaled = resize/255

# Need to change shape of "scaled"
np.expand_dims(scaled,0).shape

img_new = np.expand_dims(scaled,0)

"""After setting up above cmnd, This is way how to call model"""

y_hat = model.predict(img_new)

"""If y_hat >= 0.5, its a dog. O/w a cat. class_names = [cats,dogs] # Check in top lines"""

if y_hat>=0.5:
  print(f"{y_hat} : {class_names[1]}")
else:
  print(f"{y_hat} : {class_names[0]}")